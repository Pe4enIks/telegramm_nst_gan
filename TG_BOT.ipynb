{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "TG_BOT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oareMdbDjoGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def NST(content_image_, style_image_):\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.optim as optim\n",
        "    from PIL import Image\n",
        "    import torch.nn.functional as F\n",
        "    import torchvision.transforms as transforms\n",
        "    import torchvision.models as models\n",
        "    import copy\n",
        "    content_layers_default = ['conv_4']\n",
        "    style_layers_default = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']\n",
        "    class ContentLoss(nn.Module):\n",
        "        def __init__(self, target,):\n",
        "            super(ContentLoss, self).__init__()\n",
        "            self.target = target.detach()\n",
        "        def forward(self, input):\n",
        "            self.loss = F.mse_loss(input, self.target)\n",
        "            return input\n",
        "    class StyleLoss(nn.Module):\n",
        "        def __init__(self, target_feature):\n",
        "            super(StyleLoss, self).__init__()\n",
        "            self.target = gram_matrix(target_feature).detach()\n",
        "        def forward(self, input):\n",
        "            G = gram_matrix(input)\n",
        "            self.loss = F.mse_loss(G, self.target)\n",
        "            return input\n",
        "    class Normalization(nn.Module):\n",
        "        def __init__(self, mean, std):\n",
        "            super(Normalization, self).__init__()\n",
        "            self.mean = torch.tensor(mean).view(-1, 1, 1)\n",
        "            self.std = torch.tensor(std).view(-1, 1, 1)\n",
        "        def forward(self, img):\n",
        "            return (img - self.mean) / self.std\n",
        "    def gram_matrix(input):\n",
        "        a, b, c, d = input.size()\n",
        "        features = input.view(a * b, c * d) \n",
        "        G = torch.mm(features, features.t())\n",
        "        return G.div(a * b * c * d)\n",
        "    def image_loader(image_name):\n",
        "        image = Image.open(image_name).convert('RGB')\n",
        "        image = loader(image).unsqueeze(0)\n",
        "        return image.to(device, torch.float)\n",
        "    def get_style_model_and_losses(cnn, normalization_mean, normalization_std,\n",
        "                                  style_img, content_img,\n",
        "                                  content_layers=content_layers_default,\n",
        "                                  style_layers=style_layers_default):\n",
        "        cnn = copy.deepcopy(cnn)\n",
        "        normalization = Normalization(normalization_mean, normalization_std).to(device)\n",
        "        content_losses = []\n",
        "        style_losses = []\n",
        "        model = nn.Sequential(normalization)\n",
        "        i = 0\n",
        "        for layer in cnn.children():\n",
        "            if isinstance(layer, nn.Conv2d):\n",
        "                i += 1\n",
        "                name = 'conv_{}'.format(i)\n",
        "            elif isinstance(layer, nn.ReLU):\n",
        "                name = 'relu_{}'.format(i)\n",
        "                layer = nn.ReLU(inplace=False)\n",
        "            elif isinstance(layer, nn.MaxPool2d):\n",
        "                name = 'pool_{}'.format(i)\n",
        "            elif isinstance(layer, nn.BatchNorm2d):\n",
        "                name = 'bn_{}'.format(i)\n",
        "            else:\n",
        "                raise RuntimeError('Unrecognized layer: {}'.format(layer.__class__.__name__))\n",
        "            model.add_module(name, layer)\n",
        "            if name in content_layers:\n",
        "                target = model(content_img).detach()\n",
        "                content_loss = ContentLoss(target)\n",
        "                model.add_module(\"content_loss_{}\".format(i), content_loss)\n",
        "                content_losses.append(content_loss)\n",
        "            if name in style_layers:\n",
        "                target_feature = model(style_img).detach()\n",
        "                style_loss = StyleLoss(target_feature)\n",
        "                model.add_module(\"style_loss_{}\".format(i), style_loss)\n",
        "                style_losses.append(style_loss)\n",
        "        for i in range(len(model) - 1, -1, -1):\n",
        "            if isinstance(model[i], ContentLoss) or isinstance(model[i], StyleLoss):\n",
        "                break\n",
        "        model = model[:(i + 1)]\n",
        "        return model, style_losses, content_losses\n",
        "    def get_input_optimizer(input_img):\n",
        "        optimizer = optim.LBFGS([input_img.requires_grad_()])\n",
        "        return optimizer\n",
        "\n",
        "    def run_style_transfer(cnn, normalization_mean, normalization_std,\n",
        "                       content_img, style_img, input_img, num_steps=300,\n",
        "                       style_weight=1000000, content_weight=1):\n",
        "        model, style_losses, content_losses = get_style_model_and_losses(cnn,\n",
        "            normalization_mean, normalization_std, style_img, content_img)\n",
        "        optimizer = get_input_optimizer(input_img)\n",
        "        run = [0]\n",
        "        while run[0] <= num_steps:\n",
        "            def closure():\n",
        "                input_img.data.clamp_(0, 1)\n",
        "                optimizer.zero_grad()\n",
        "                model(input_img)\n",
        "                style_score = 0\n",
        "                content_score = 0\n",
        "                for sl in style_losses:\n",
        "                    style_score += sl.loss\n",
        "                for cl in content_losses:\n",
        "                    content_score += cl.loss\n",
        "                style_score *= style_weight\n",
        "                content_score *= content_weight\n",
        "                loss = style_score + content_score\n",
        "                loss.backward()\n",
        "                run[0] += 1\n",
        "                return style_score + content_score\n",
        "            optimizer.step(closure)\n",
        "        input_img.data.clamp_(0, 1)\n",
        "        return input_img\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    imsize = 512 if torch.cuda.is_available() else 256\n",
        "    loader = transforms.Compose([\n",
        "        transforms.Resize(imsize),\n",
        "        transforms.CenterCrop(imsize),\n",
        "        transforms.ToTensor()])\n",
        "    style_img = image_loader(style_image_)\n",
        "    content_img = image_loader(content_image_)\n",
        "    cnn = models.vgg19(pretrained=True).features.to(device).eval()\n",
        "    cnn_normalization_mean = torch.tensor([0.485, 0.456, 0.406]).to(device)\n",
        "    cnn_normalization_std = torch.tensor([0.229, 0.224, 0.225]).to(device)\n",
        "    input_img = content_img.clone()\n",
        "    epochs = 1000 if torch.cuda.is_available() else 300\n",
        "    output = run_style_transfer(cnn, cnn_normalization_mean, cnn_normalization_std,\n",
        "                            content_img, style_img, input_img,num_steps=epochs)\n",
        "    unloader = transforms.ToPILImage() \n",
        "    image = output.cpu().clone()\n",
        "    image = image.squeeze(0)\n",
        "    image = unloader(image)\n",
        "    image.save(\"result.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVJFRyVP9CS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GAN():    \n",
        "    import sys\n",
        "    sys.path.insert(0, \"stylegan\")\n",
        "    import dnnlib\n",
        "    import os\n",
        "    import pickle\n",
        "    import numpy as np\n",
        "    import PIL.Image\n",
        "    import dnnlib\n",
        "    import dnnlib.tflib as tflib\n",
        "    import config\n",
        "    tflib.init_tf()\n",
        "    with open('/content/drive/My Drive/stylegan.pkl', 'rb') as f:\n",
        "        _G, _D, Gs = pickle.load(f)\n",
        "    rnd = np.random.RandomState()\n",
        "    latents = rnd.randn(1, Gs.input_shape[1])\n",
        "    fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    images = Gs.run(latents, None, truncation_psi=0.7, randomize_noise=True, output_transform=fmt)\n",
        "    png_filename = \"celeba.jpg\"\n",
        "    PIL.Image.fromarray(images[0], 'RGB').save(png_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhwY2L-mF7Pq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "68bc4020-2d0b-4f73-8ee6-555859e760c5"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!git clone https://github.com/NVlabs/stylegan.git\n",
        "!pip install pyTelegramBotAPI\n",
        "!pip install pysocks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Cloning into 'stylegan'...\n",
            "remote: Enumerating objects: 83, done.\u001b[K\n",
            "remote: Total 83 (delta 0), reused 0 (delta 0), pack-reused 83\u001b[K\n",
            "Unpacking objects: 100% (83/83), done.\n",
            "Collecting pyTelegramBotAPI\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/1d/40c1fde174731bd58f014721a37c28d35210aa39c42c3e8b1659374a9bec/pyTelegramBotAPI-3.7.1.tar.gz (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pyTelegramBotAPI) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pyTelegramBotAPI) (1.12.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pyTelegramBotAPI) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pyTelegramBotAPI) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pyTelegramBotAPI) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pyTelegramBotAPI) (3.0.4)\n",
            "Building wheels for collected packages: pyTelegramBotAPI\n",
            "  Building wheel for pyTelegramBotAPI (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyTelegramBotAPI: filename=pyTelegramBotAPI-3.7.1-cp36-none-any.whl size=50883 sha256=845ae58ef22065514768fb05d382c1ab02fad55377e0cf7e2a0f17a2dc358fb1\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/b2/2c/eac6af3343b21f907123ce013d20ad5ad70c2c3731072d98bf\n",
            "Successfully built pyTelegramBotAPI\n",
            "Installing collected packages: pyTelegramBotAPI\n",
            "Successfully installed pyTelegramBotAPI-3.7.1\n",
            "Requirement already satisfied: pysocks in /usr/local/lib/python3.6/dist-packages (1.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg8wnoDe-33Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "5471a37a-41fb-48b3-a7d8-91a0e6f86fd2"
      },
      "source": [
        "import telebot\n",
        "from telebot import apihelper\n",
        "import os\n",
        "from google.colab import drive\n",
        "TOKEN = \"your_token\"\n",
        "apihelper.proxy = {'https':'socks5://student:TH8FwlMMwWvbJF8FYcq0@178.128.203.1:1080'}\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_zcaaHSGh3O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "98edf0e7-81e2-4a1d-c1c7-2ca884ab2ade"
      },
      "source": [
        "bot = telebot.TeleBot(TOKEN)\n",
        "arr = [0]\n",
        "@bot.message_handler(commands=['help'])\n",
        "def help(message):\n",
        "    bot.send_message(message.chat.id, \"WARNING: Didn't send to bot 2 photo in one message, give for bot 1-st image - content, 2-nd - style, wait answer please or bot will die)), tnx:)\\nYou can load 2 photo without command, use\\n/combine to merge content and style, GLHF:)\\nIf you use /GAN button, bot generate random people photo in high resolution.\")\n",
        "@bot.message_handler(commands=['start'])\n",
        "def start(message):\n",
        "    user_markup = telebot.types.ReplyKeyboardMarkup(True, False)\n",
        "    user_markup.row('/combine', '/help')\n",
        "    user_markup.row('/GAN')\n",
        "    bot.send_message(message.from_user.id, \"Hello!\", reply_markup=user_markup)\n",
        "    print(message.chat.id)\n",
        "    bot.send_message(message.chat.id, \"Use /help for info\")\n",
        "@bot.message_handler(commands=['GAN'])\n",
        "def gan_res(message):\n",
        "    try:\n",
        "        bot.send_message(message.chat.id, \"Please wait less than 2 minutes\")\n",
        "        GAN()\n",
        "        image = open('celeba.jpg', 'rb')\n",
        "        bot.send_photo(message.chat.id, image)\n",
        "        os.remove(\"celeba.jpg\")\n",
        "        print(\"success\")\n",
        "    except:\n",
        "        bot.send_message(message.chat.id, \"GAN ERROR\")\n",
        "        print(\"error\")\n",
        "@bot.message_handler(commands=['combine'])\n",
        "def combine(message):\n",
        "    try:\n",
        "        bot.send_message(message.chat.id, \"Please wait 5-10 minutes\")\n",
        "        NST(\"name0.jpg\", \"name1.jpg\")\n",
        "        image = open('result.jpg', 'rb')\n",
        "        bot.send_photo(message.chat.id, image)\n",
        "        os.remove(\"name0.jpg\")\n",
        "        os.remove(\"name1.jpg\")\n",
        "        os.remove(\"result.jpg\")\n",
        "        print(\"sucess\")\n",
        "    except:\n",
        "        bot.send_message(message.chat.id, \"Maybe you didn't load 2 photos\")\n",
        "        print(\"error\")\n",
        "@bot.message_handler(content_types=['photo'])\n",
        "def photo(message):\n",
        "    if arr[0] == 0:\n",
        "        print(\"Content\")\n",
        "        print('message.photo =', message.photo)\n",
        "        fileID = message.photo[-1].file_id\n",
        "        print('fileID =', fileID)\n",
        "        file_info = bot.get_file(fileID)\n",
        "        print('file.file_path =', file_info.file_path)\n",
        "        downloaded_file = bot.download_file(file_info.file_path)\n",
        "        name = arr[0]\n",
        "        new_file = open(\"name{}.jpg\".format(name),'wb')\n",
        "        new_file.write(downloaded_file)\n",
        "        new_file.close()\n",
        "        arr[0] = 1\n",
        "        bot.send_message(message.chat.id, \"Content Loaded\")\n",
        "    else:\n",
        "        print(\"Style\")\n",
        "        print('message.photo =', message.photo)\n",
        "        fileID = message.photo[-1].file_id\n",
        "        print('fileID =', fileID)\n",
        "        file_info = bot.get_file(fileID)\n",
        "        print('file.file_path =', file_info.file_path)\n",
        "        downloaded_file = bot.download_file(file_info.file_path)\n",
        "        name = arr[0]\n",
        "        new_file = open(\"name{}.jpg\".format(name),'wb')\n",
        "        new_file.write(downloaded_file)\n",
        "        new_file.close()\n",
        "        arr[0] = 0\n",
        "        bot.send_message(message.chat.id, \"Style Loaded\")\n",
        "bot.polling()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From stylegan/dnnlib/tflib/tfutil.py:34: The name tf.Dimension is deprecated. Please use tf.compat.v1.Dimension instead.\n",
            "\n",
            "WARNING:tensorflow:From stylegan/dnnlib/tflib/tfutil.py:74: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From stylegan/dnnlib/tflib/tfutil.py:128: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "1\n",
            "WARNING:tensorflow:From stylegan/dnnlib/tflib/tfutil.py:97: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From stylegan/dnnlib/tflib/tfutil.py:109: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From stylegan/dnnlib/tflib/tfutil.py:132: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From stylegan/dnnlib/tflib/network.py:142: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From stylegan/dnnlib/tflib/network.py:150: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From stylegan/dnnlib/tflib/tfutil.py:76: The name tf.VariableScope is deprecated. Please use tf.compat.v1.VariableScope instead.\n",
            "\n",
            "WARNING:tensorflow:From stylegan/dnnlib/tflib/network.py:151: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From stylegan/dnnlib/tflib/network.py:154: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From stylegan/dnnlib/tflib/network.py:182: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From stylegan/dnnlib/tflib/tfutil.py:200: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From <string>:364: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "success\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB3nZT8HNwqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}